{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9252f637",
   "metadata": {},
   "source": [
    "최종 구성 \n",
    "- 공통 \n",
    "    - `법령키`\n",
    "    - `법령명_한글`\n",
    "    - `법령_ID`\n",
    "    - `시행일자`\n",
    "    - `공포일자`\n",
    "    - `조문번호`\n",
    "    - `조문키`\n",
    "    - `조문내용`\n",
    "    - `조문시행일자`\n",
    "    - `조문여부`\n",
    "    -----\n",
    "    - `chunk_length` : 이번 text의 길이 \n",
    "- 조문\n",
    "    - `항` 추가\n",
    "        - `hang_no` : 항이 있다면 몇 개인지 \n",
    "        - `ho_no` : 호가 있다면 몇 개인지\n",
    "        - `mock_no` : 목이 있다면 몇 개인지\n",
    "    - `chunk_no`: 길어서 몇 개로 끊어졌다면 몇 번째 청크인지\n",
    "    - `total_parts` : 길어서 몇 개로 끊었다면 총 몇 개의 청크인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf21721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "os.chdir('C:/Users/SAMSUNG/Desktop/Grad_School/RAG_LAW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5293efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class ParsingAndChunking():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def read_json_file(self, law_json_path):\n",
    "        \"\"\"파일 경로 받아서 파일 열기\"\"\"\n",
    "        with open(law_json_path, \"r\", encoding = \"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    \n",
    "    def norm_date(self, date):\n",
    "        \"\"\"2025006 -> 2025-09-06\"\"\"\n",
    "        if not date:\n",
    "            return None\n",
    "        return f\"{date[:4]}-{date[4:6]}-{date[6:]}\"\n",
    "\n",
    "    def norm_hang_no(self, hang_num):\n",
    "        \"\"\"'①' -> '1', '②' -> '2', 그대로/None 허용\"\"\"\n",
    "        # 동그리 숫자들 정리하기\n",
    "        CIRCLED = dict(zip(\"①②③④⑤⑥⑦⑧⑨⑩\", map(str, range(1,11))))\n",
    "        if not hang_num: \n",
    "            return None\n",
    "        return CIRCLED.get(hang_num, hang_num)\n",
    "\n",
    "    def norm_ho_no(self, ho_num):\n",
    "        \"\"\"'5.' -> '5'\"\"\"\n",
    "        if not ho_num:\n",
    "            return None\n",
    "        return ho_num.rstrip(\".\").strip()\n",
    "\n",
    "    def norm_mock_no(self, mock_num):\n",
    "        \"\"\"'가.' -> '1'\"\"\"\n",
    "        GANADA = {f\"{num}.\" : str(i) for i, num in enumerate(\"가나다라마바사아자차카타파하\", start = 1)}\n",
    "        if not mock_num:\n",
    "            return None\n",
    "        return GANADA.get(mock_num, mock_num)\n",
    "\n",
    "    def build_chunk_id(self, law_id, junmun_key, text_type, branch_no = None, hang_no = None, ho_no = None, mock_no = None):\n",
    "        \"\"\"\n",
    "        이번 chunk의 전체 제목 정하기\n",
    "        text_type : 전문/~조\n",
    "        최종 예시) LAW-011357-제 1장-3조-2항-5호...\n",
    "        \"\"\"\n",
    "        base = f\"LAW-{law_id}-{junmun_key}-{text_type}\"\n",
    "        if branch_no is not None:\n",
    "            base += f\"({branch_no})\"\n",
    "        if hang_no is not None:\n",
    "            base += f\"-{hang_no}항\"\n",
    "        if ho_no is not None:\n",
    "            base += f\"-{ho_no}호\"\n",
    "        if mock_no is not None:\n",
    "            base += f\"-{mock_no}목\"    \n",
    "        return base\n",
    "    \n",
    "    def as_list(self, x):\n",
    "        if not x:\n",
    "            return []\n",
    "        return x if isinstance(x, list) else [x]\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        if isinstance(text, list):\n",
    "            text = \" \".join(map(str, text))\n",
    "        # <개정 ~> 부분 없애기\n",
    "        text = re.sub(r'<[^>]+>', \"\", text) \n",
    "        # [ ] -> ( )\n",
    "        text = text.replace(\"[\", \"(\"). replace(\"]\", \")\")\n",
    "        # \\ 없애기\n",
    "        text = text.replace(\"\\\\\", \"\")\n",
    "        #「 」-> \" \"\n",
    "        text = text.replace(\"「\", '\"').replace(\"」\", '\"')\n",
    "        # 요상한 공백들 없애기\n",
    "        text = text.replace(\"\\u3000\", \" \").replace(\"\\xa0\", \" \")\n",
    "        # 공백 여러 개, 탭 -> 공백 하나로\n",
    "        text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "        # 빈 줄 여러 개 -> 엔터 한 번으로\n",
    "        text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
    "        return text.strip()\n",
    "        \n",
    "\n",
    "    def get_basic_information(self, data):\n",
    "        ### 기본 정보 - law_information\n",
    "        law_information = {\n",
    "        # 법령키\n",
    "        'law_key' : data['법령']['법령키'],\n",
    "        # 기본정보\n",
    "        'law_name' : data['법령']['기본정보']['법령명_한글'],\n",
    "        'law_id' : data['법령']['기본정보']['법령ID'],\n",
    "        'ministry' : data['법령']['기본정보']['소관부처']['content'],\n",
    "        'eff_date' : data['법령']['기본정보']['시행일자'],\n",
    "        'prom_date' : data['법령']['기본정보']['공포일자']}\n",
    "\n",
    "        return law_information\n",
    "    \n",
    "    def get_jomun_information(self, data, law_id, law_information):\n",
    "        chunks = []\n",
    "\n",
    "        ### 추가 : 법률 이름 저장해두기\n",
    "        embed_law_name = law_information.get(\"law_name\", \"\")   \n",
    "        ### 추가 : 전문 정보 저장\n",
    "        current_pyeon = \"\"\n",
    "        current_jang = \"\" # 현재의 전문 (~절일 수도)\n",
    "        junmun_content = \"\" # 전체 완성된 전문\n",
    "        # 전문 없는 경우 \n",
    "        junmun_num = \"\"\n",
    "        junmun_key = \"\"\n",
    "\n",
    "        # 조문 \n",
    "        for jomun in data['법령']['조문']['조문단위']:\n",
    "            jomun_num = jomun['조문번호']\n",
    "            jomun_key = jomun['조문키']\n",
    "            jomun_date = self.norm_date(jomun['조문시행일자'])\n",
    "            text_type = jomun['조문여부'] # 조문/전문\n",
    "            \n",
    "            jomun_content = self.clean_text(jomun['조문내용']) # 전문이든 조문이든 (전문인 경우 continue)\n",
    "\n",
    "            if text_type == \"전문\":\n",
    "                if embed_law_name == \"자본시장과 금융투자업에 관한 법률\":\n",
    "                    match_pyeon = re.match(r\"^(제.+편)\", jomun_content.strip())\n",
    "                    match_jang = re.match(r\"^(제.+장)\", jomun_content.strip())\n",
    "                    is_pyeon = bool(match_pyeon)\n",
    "                    is_jang = bool(match_jang)\n",
    "                    # ~편인지 확인\n",
    "                    if is_pyeon:\n",
    "                        current_pyeon = jomun_content\n",
    "                        current_jang = \"\" # 장 리셋\n",
    "                        junmun_content = current_pyeon\n",
    "                        junmun_num = match_pyeon.group(1)\n",
    "                        junmun_key = jomun_content[:3]\n",
    "                    # ~장인지 확인\n",
    "                    elif is_jang:\n",
    "                        current_jang = jomun_content\n",
    "                        junmun_content = f\"{current_pyeon} {current_jang}\"\n",
    "                    else:\n",
    "                        junmun_content = f\"{current_pyeon} {current_jang} {jomun_content}\"\n",
    "                        \n",
    "                else:\n",
    "                    match = re.match(r\"^(제.+장)\", jomun_content.strip())\n",
    "                    is_jang = bool(match)\n",
    "                     # ~장인지 확인\n",
    "                    if is_jang:\n",
    "                        junmun_content = jomun_content\n",
    "                        current_jang = jomun_content\n",
    "                        junmun_num = match.group(1)\n",
    "                        junmun_key = jomun_content[:3]\n",
    "                    else:\n",
    "                        # ~장 + ~절 붙여서\n",
    "                        junmun_content = f\"{current_jang} {jomun_content}\"\n",
    "                continue\n",
    "\n",
    "            jomun_branch = jomun.get(\"조문가지번호\", 0)\n",
    "            is_branch = bool(jomun_branch)\n",
    "            \n",
    "            # 조문 자체의 정보 저장\n",
    "            base_meta = {\n",
    "                \"law_meta\" : law_information,\n",
    "                \"junmun_num\" : junmun_num,\n",
    "                \"jomun_key\" : jomun_key,\n",
    "                \"jomun_num\" : jomun_num,\n",
    "                \"jomun_date\" : jomun_date,\n",
    "                \"text_type\" : text_type,\n",
    "                \"is_branch\" : is_branch,\n",
    "                \"jomun_branch\" : jomun_branch\n",
    "            }\n",
    "\n",
    "            jomun_with_jo = f\"{jomun_num}조\" if jomun_num else \"조문\"\n",
    "            branch_with_gaji = f\"(가지{jomun_branch})\" if is_branch else \"\"\n",
    "            jomun_with_branch = f\"{jomun_with_jo}{branch_with_gaji}\"\n",
    "\n",
    "            ### 추가 : 법률 - 전문\n",
    "            emb_junmun_context = f\"{embed_law_name} {junmun_content}\"\n",
    "            \n",
    "            # 조문 - 항 있음\n",
    "            hangs = self.as_list(jomun.get(\"항\"))\n",
    "            hangs_cnt = len(hangs) # 이번 조문에 항이 몇 개인지\n",
    "\n",
    "            ### 추가 : 법률 - 전문 - 조문\n",
    "            emb_jomun_context = f\"{emb_junmun_context} {jomun_content}\"\n",
    "\n",
    "            # 항 없이 조문만 있는 경우\n",
    "            if not hangs:\n",
    "                chunk = {\n",
    "                    **base_meta,\n",
    "                    \"chunk_id\" : self.build_chunk_id(law_id, junmun_key, jomun_with_jo, jomun_branch),\n",
    "                    \"section_type\" : \"조문\",\n",
    "                    \"path\" : jomun_with_branch,\n",
    "                    \"hangs_cnt\" : 0,\n",
    "                    \"original_text\" : jomun_content,\n",
    "                    \"embedding_text\" : emb_jomun_context\n",
    "                }\n",
    "                chunks.append(chunk)\n",
    "                continue\n",
    "\n",
    "            for hang in hangs:\n",
    "                # 항 정보부터 가져오기\n",
    "                hang_no_raw = hang.get(\"항번호\")\n",
    "                hang_no = self.norm_hang_no(hang_no_raw)\n",
    "                hang_text = self.clean_text(hang.get(\"항내용\"))\n",
    "\n",
    "                ### 추가 : 법률 - 전문 - 조문 - (항)\n",
    "                emb_hang_context = f\"{emb_jomun_context} {hang_text}\" if hang_text else emb_jomun_context\n",
    "\n",
    "                # 호 정보 가져오기\n",
    "                hos = self.as_list(hang.get(\"호\"))\n",
    "                hos_cnt = len(hos)\n",
    "                is_no_hang = bool(hos) and not (hang.get(\"항번호\") or hang.get(\"항내용\")) # 항 x \n",
    "\n",
    "                # 1. [항 | ... ]의 구조 (항의 내용이 없는 경우)\n",
    "                if is_no_hang:\n",
    "                    for ho in hos:\n",
    "                        ho_no_raw = ho.get(\"호번호\")\n",
    "                        ho_no = self.norm_ho_no(ho_no_raw)\n",
    "                        ho_text = self.clean_text(ho.get(\"호내용\"))\n",
    "\n",
    "                        ### 추가 : 법률 - 전문 - 조문 - (항) - (호) -> 항은 없음\n",
    "                        emb_ho_context = f\"{emb_hang_context} {ho_text}\" if ho_text else emb_hang_context\n",
    "\n",
    "                        # 호와 목도 마찬가지.. \n",
    "                        mocks = self.as_list(ho.get(\"목\"))\n",
    "                        mocks_cnt = len(mocks)\n",
    "\n",
    "                        # [항 | 호]의 구조\n",
    "                        if ho_text:\n",
    "                            chunk = {\n",
    "                                **base_meta,\n",
    "                                \"chunk_id\" : self.build_chunk_id(law_id, junmun_key, jomun_with_jo, jomun_branch, hang_no = None, ho_no = ho_no),\n",
    "                                \"section_type\" : \"호\",\n",
    "                                \"path\" : f\"{junmun_content} - {jomun_with_branch} - {ho_no}호\",\n",
    "                                \"ho_no\" : ho_no,\n",
    "                                \"hangs_cnt\" : hangs_cnt,\n",
    "                                \"hos_cnt\" : hos_cnt,\n",
    "                                \"original_text\" : ho_text,\n",
    "                                \"embedding_text\" : emb_ho_context,\n",
    "                                \"parent\": {                            \n",
    "                                \"jomun_label\": jomun_with_jo,\n",
    "                                \"junmun_text\" : junmun_content,\n",
    "                                \"jomun_text\": jomun_content\n",
    "                                }\n",
    "                            }\n",
    "                            chunks.append(chunk)\n",
    "\n",
    "                        # [항 | 호 - 목]의 구조\n",
    "                        for mock in mocks:\n",
    "                            mock_no_raw = mock.get(\"목번호\")\n",
    "                            mock_no = self.norm_mock_no(mock_no_raw)\n",
    "                            mock_text = self.clean_text(mock.get(\"목내용\"))\n",
    "\n",
    "                            ### 추가 : 법률 - 전문 - 조문 - (항) - (호) - (목) -> 항은 없음\n",
    "                            emb_mock_context = f\"{emb_ho_context} {mock_text}\" if mock_text else emb_ho_context\n",
    "\n",
    "                            if mock_text:\n",
    "                                chunk = {\n",
    "                                    **base_meta,\n",
    "                                    \"chunk_id\" : self.build_chunk_id(law_id, junmun_key, jomun_with_jo, jomun_branch, hang_no = None, ho_no = ho_no, mock_no = mock_no),\n",
    "                                    \"section_type\" : \"목\",\n",
    "                                    \"path\" : f\"{junmun_content} - {jomun_with_branch} - {ho_no}호 - {mock_no}목\",\n",
    "                                    \"ho_no\" : ho_no,\n",
    "                                    \"mock_no\" : mock_no,\n",
    "                                    \"hangs_cnt\" : hangs_cnt,\n",
    "                                    \"hos_cnt\" : hos_cnt,\n",
    "                                    \"mocks_cnt\" : mocks_cnt,\n",
    "                                    \"original_text\" : mock_text,\n",
    "                                    \"embedding_text\" : emb_mock_context,\n",
    "                                    \"parent\": {                            \n",
    "                                    \"jomun_label\": jomun_with_jo,\n",
    "                                    \"junmun_text\" : junmun_content,\n",
    "                                    \"jomun_text\": jomun_content,\n",
    "                                    \"ho_text\" : ho_text\n",
    "                                    }\n",
    "                                }\n",
    "                                chunks.append(chunk)\n",
    "                    continue\n",
    "                \n",
    "                # [항]에서 끝난다면\n",
    "                if hang_text:\n",
    "                    chunk = {\n",
    "                        **base_meta,\n",
    "                        \"chunk_id\" : self.build_chunk_id(law_id, junmun_key, jomun_with_jo, jomun_branch, hang_no),\n",
    "                        \"section_type\" : \"항\",\n",
    "                        \"path\" : f\"{junmun_content} - {jomun_with_branch} - {hang_no}항\",\n",
    "                        \"hang_no\" : hang_no,\n",
    "                        \"hangs_cnt\" : hangs_cnt,\n",
    "                        \"original_text\" : hang_text,\n",
    "                        \"embedding_text\" : emb_hang_context,\n",
    "                        \"parent\": {                            \n",
    "                        \"jomun_label\": jomun_with_jo,\n",
    "                        \"junmun_text\" : junmun_content,\n",
    "                        \"jomun_text\": jomun_content\n",
    "                        }\n",
    "                    }\n",
    "                    chunks.append(chunk)\n",
    "\n",
    "                if not hos:\n",
    "                    continue\n",
    "\n",
    "                for ho in hos:\n",
    "                    ho_no_raw = ho.get(\"호번호\")\n",
    "                    ho_no = self.norm_ho_no(ho_no_raw)\n",
    "                    ho_text = self.clean_text(ho.get(\"호내용\"))\n",
    "\n",
    "                    ### 추가 : 법률 - 전문 - 조문 - (항) - (호) \n",
    "                    emb_ho_context = f\"{emb_hang_context} {ho_text}\" if ho_text else emb_hang_context\n",
    "                    \n",
    "                    mocks = self.as_list(ho.get(\"목\"))\n",
    "                    mocks_cnt = len(mocks)\n",
    "\n",
    "                    # [항 - 호]의 구조\n",
    "                    if ho_text:\n",
    "                        chunk = {\n",
    "                            **base_meta,\n",
    "                            \"chunk_id\" : self.build_chunk_id(law_id, junmun_key, jomun_with_jo, jomun_branch, hang_no, ho_no),\n",
    "                            \"section_type\" : \"호\",\n",
    "                            \"path\" : f\"{junmun_content} - {jomun_with_branch} - {hang_no}항 - {ho_no}호\",\n",
    "                            \"hang_no\": hang_no,\n",
    "                            \"ho_no\" : ho_no,\n",
    "                            \"hangs_cnt\" : hangs_cnt,\n",
    "                            \"hos_cnt\" : hos_cnt,\n",
    "                            \"original_text\" : ho_text,\n",
    "                            \"embedding_text\" : emb_ho_context,\n",
    "                            \"parent\": {                            \n",
    "                            \"jomun_label\": jomun_with_jo,\n",
    "                            \"junmun_text\" : junmun_content,\n",
    "                            \"jomun_text\": jomun_content,\n",
    "                            \"hang_text\" : hang_text\n",
    "                            }\n",
    "                        }\n",
    "                        chunks.append(chunk)\n",
    "\n",
    "                    if not mocks:\n",
    "                        continue\n",
    "\n",
    "                    # [항 - 호 - 목]의 구조\n",
    "                    for mock in mocks:\n",
    "                        mock_no_raw = mock.get(\"목번호\")\n",
    "                        mock_no = self.norm_mock_no(mock_no_raw)\n",
    "                        mock_text = self.clean_text(mock.get(\"목내용\"))\n",
    "\n",
    "                        ### 추가 : 법률 - 전문 - 조문 - (항) - (호) - (목)\n",
    "                        emb_mock_context = f\"{emb_ho_context} {mock_text}\" if mock_text else emb_ho_context\n",
    "\n",
    "                        if mock_text:\n",
    "                            chunk = {\n",
    "                                **base_meta,\n",
    "                                \"chunk_id\" : self.build_chunk_id(law_id, junmun_key, jomun_with_jo, jomun_branch, hang_no, ho_no, mock_no),\n",
    "                                \"section_type\" : \"목\",\n",
    "                                \"path\" : f\"{junmun_content} - {jomun_with_branch} - {hang_no}항 - {ho_no}호 - {mock_no}목\",\n",
    "                                \"hang_no\": hang_no,\n",
    "                                \"ho_no\" : ho_no,\n",
    "                                \"mock_no\" : mock_no,\n",
    "                                \"hangs_cnt\" : hangs_cnt,\n",
    "                                \"hos_cnt\" : hos_cnt,\n",
    "                                \"mocks_cnt\" : mocks_cnt,\n",
    "                                \"original_text\" : mock_text,\n",
    "                                \"embedding_text\" : emb_mock_context,\n",
    "                                \"parent\": {                            \n",
    "                                \"jomun_label\": jomun_with_jo,\n",
    "                                \"junmun_text\" : junmun_content,\n",
    "                                \"jomun_text\": jomun_content,\n",
    "                                \"hang_text\" : hang_text,\n",
    "                                \"ho_text\" : ho_text\n",
    "                                }\n",
    "                            }\n",
    "                            chunks.append(chunk)\n",
    "\n",
    "        return chunks\n",
    "    \n",
    "    def chunking(self, chunks, max_len, child_max_len):\n",
    "        \"\"\"\n",
    "        Input : 파싱 완료된 chunks\n",
    "        - 각 chunk의 길이 측정 \n",
    "        - 'embedding_text'가 512를 넘는 경우에는...\n",
    "            - parent, child 분할\n",
    "            - parent, child 문장 단위로 분할하기\n",
    "            - child가 200자 넘지 않도록 청킹하기\n",
    "            - parent 부분으로 나머지 채우기 (512 넘지 않게, 대신 뒷 맥락부터)\n",
    "            - 나머지 부분 똑같이 가져오고, 'embedding_text'만 바꿔서 새롭게 저장\n",
    "            - 'chunk_parts' : 몇 개로 나누었는지\n",
    "            - 'chunk_no' : 몇 번째 청크인지 \n",
    "        Output : 청킹까지 완료된 chunks\n",
    "        \"\"\"\n",
    "        output = []\n",
    "        for chunk in chunks:\n",
    "            chunk_len = len(chunk.get(\"embedding_text\"))\n",
    "\n",
    "            # max_len 안 넘으면\n",
    "            if chunk_len <= max_len:\n",
    "                new_chunk = {**chunk}\n",
    "                new_chunk[\"text_len\"] = chunk_len\n",
    "                new_chunk[\"chunk_parts\"] = 1\n",
    "                new_chunk[\"chunk_no\"] = 1\n",
    "                output.append(new_chunk)\n",
    "\n",
    "            else:\n",
    "                original_text = chunk.get(\"original_text\", \"\")\n",
    "                embedding_text = chunk.get(\"embedding_text\", \"\")\n",
    "\n",
    "                if not embedding_text.endswith(original_text):\n",
    "                    print(f\"오류 : {chunk.get('chunk_id')} : embedding_text가 original_text로 끝나지 않습니다.\")\n",
    "                    output.append(chunk)\n",
    "                    continue\n",
    "\n",
    "                parent = embedding_text[:-len(original_text)].rstrip()\n",
    "                child = original_text\n",
    "\n",
    "                # child가 길면\n",
    "                if len(child) > child_max_len:\n",
    "                    child_merged = self.split_sentences(child)\n",
    "                    child_packs = self.pack_sentences(child_merged, child_max_len)\n",
    "\n",
    "                # child 안 길면 (parent가 긺)\n",
    "                else:   \n",
    "                    child_packs = [child]\n",
    "\n",
    "                packs_num = len(child_packs)\n",
    "\n",
    "                # parent 쪼개기\n",
    "                parents_merged = self.split_sentences(parent)\n",
    "\n",
    "                for i, child_pack in enumerate(child_packs, 1):\n",
    "                    parent_budget = max_len - len(child_pack) - 1\n",
    "\n",
    "                    if parent_budget < 0:\n",
    "                        parent_budget = 0\n",
    "                    \n",
    "                    parent_pack = []\n",
    "                    parent_pack_len = 0\n",
    "\n",
    "                    for parent_sent in reversed(parents_merged):\n",
    "                        parent_sent = parent_sent.strip()\n",
    "                        if not parent_sent:\n",
    "                            continue\n",
    "\n",
    "                        parent_sent_len = len(parent_sent)\n",
    "                        expected_len = parent_pack_len + parent_sent_len + (1 if parent_pack else 0) # 처음은 0, 그 다음부터는 띄어쓰기\n",
    "\n",
    "                        if expected_len > parent_budget:\n",
    "                            break \n",
    "\n",
    "                        parent_pack.insert(0, parent_sent)\n",
    "                        parent_pack_len = expected_len\n",
    "                    \n",
    "                    final_parent_pack = \" \".join(parent_pack)\n",
    "                    final_pack = f\"{final_parent_pack} {child_pack}\"\n",
    "\n",
    "                    new_chunk = {**chunk}\n",
    "                    new_chunk[\"original_text\"] = child_pack\n",
    "                    new_chunk[\"embedding_text\"] = final_pack\n",
    "                    new_chunk[\"text_len\"] = len(final_pack)\n",
    "                    new_chunk[\"chunk_parts\"] = packs_num\n",
    "                    new_chunk[\"chunk_no\"] = i\n",
    "\n",
    "                    original_chunk_id = new_chunk.get(\"chunk_id\", \"chunk\")\n",
    "                    new_chunk[\"chunk_id\"] = f\"{original_chunk_id}_chunk{i}\"\n",
    "\n",
    "                    output.append(new_chunk)\n",
    "                \n",
    "\n",
    "        return output\n",
    "\n",
    "    def split_sentences(self, text) -> List[str]:\n",
    "        \"\"\"텍스트 문장 단위로 나누기 \n",
    "        -> List[\"안녕하세요\", \"만나서 반가워요\"]\n",
    "        - 기준 : 마침표, 물음표, 느낌표 등 + 숫자 리스트 (1. ), 한글 목차 (가. ), 원문자(①)\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        if isinstance(text, list):\n",
    "            s = \" \".join(map(str, text))\n",
    "        else:\n",
    "            s = str(text)\n",
    "        # 공백 제거\n",
    "        s = \" \".join(s.split())\n",
    "\n",
    "        pattern = r'(?:(?<=[.!?])(?<!\\d\\.)\\s+)|(?:\\s+(?=(?:\\d+\\.|[가-하]\\.|[①-⑮])\\s))'\n",
    "        SENT_SEP = re.compile(pattern)\n",
    "        parts = SENT_SEP.split(s)\n",
    "        parts = [p.strip() for p in parts if p and p.strip()]\n",
    "\n",
    "        # '다만'으로 시작하는 문장의 경우, 앞 문장까지 끌어오기\n",
    "        merged = []\n",
    "        for sent in parts:\n",
    "            if sent.startswith(\"다만\") and merged:\n",
    "                merged[-1] = merged[-1] + \" \" + sent\n",
    "            else:\n",
    "                merged.append(sent)\n",
    "        return merged\n",
    "\n",
    "    def pack_sentences(self, merged, max_len):\n",
    "        \"\"\"문장 단위로 분할된 문장 리스트를 길이에 맞게 패킹\"\"\"\n",
    "        packs = []\n",
    "        pack = []\n",
    "        pack_len = 0\n",
    "\n",
    "        for sent in merged:\n",
    "            sent = sent.strip()\n",
    "            sent_len = len(sent) + (1 if pack else 0)\n",
    "\n",
    "            if pack_len + sent_len <= max_len:\n",
    "                pack.append(sent)\n",
    "                pack_len += sent_len\n",
    "            else:\n",
    "                if pack:\n",
    "                    packs.append(\" \".join(pack))\n",
    "                if len(sent) <= max_len:\n",
    "                    pack = [sent]\n",
    "                    pack_len = len(sent)\n",
    "                else:\n",
    "                    while len(sent) > max_len:\n",
    "                        packs.append(sent[:max_len])\n",
    "                        sent = sent[max_len:]\n",
    "                    if sent:\n",
    "                        pack = [sent]\n",
    "                        pack_len = len(sent)\n",
    "                    else:\n",
    "                        pack = []\n",
    "                        pack_len = 0\n",
    "        if pack:\n",
    "            packs.append(\" \".join(pack))\n",
    "\n",
    "        return packs\n",
    "\n",
    "    def save_json_file(self, output, file_name):\n",
    "        file_path = f'DATA/Parsed/{file_name}_parsed.json'\n",
    "        with open(file_path, \"w\", encoding = 'utf-8') as f:\n",
    "            json.dump(output, f, ensure_ascii = False, indent = 4)\n",
    "\n",
    "\n",
    "    def parse_and_chunk(self, folder_name):\n",
    "        law_jsons_folder = Path(f\"DATA/{folder_name}\")\n",
    "        law_json_paths = list[Path](law_jsons_folder.glob(\"*.json\"))\n",
    "        laws_parsed_chunked = []\n",
    "\n",
    "        for law_json_path in law_json_paths:\n",
    "            data = self.read_json_file(law_json_path)\n",
    "            law_information = self.get_basic_information(data)\n",
    "            law_id = law_information['law_key']\n",
    "            law_name = law_information['law_name']\n",
    "            chunks = self.get_jomun_information(data, law_id, law_information)\n",
    "            output = self.chunking(chunks, max_len = 250, child_max_len = 200)\n",
    "            self.save_json_file(output, law_name)\n",
    "            print(f\"{law_name} 파싱 완료 !\")\n",
    "            laws_parsed_chunked.extend(output)\n",
    "\n",
    "        return laws_parsed_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청킹 없이 파싱만 진행\n",
    "p_c = ParsingAndChunking()\n",
    "folder_name = \"Laws\"\n",
    "law_jsons_folder = Path(f\"DATA/Raw/{folder_name}\")\n",
    "law_json_paths = list[Path](law_jsons_folder.glob(\"*.json\"))\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "for law_json_path in law_json_paths:\n",
    "    data = p_c.read_json_file(law_json_path)\n",
    "    law_information = p_c.get_basic_information(data)\n",
    "    law_id = law_information['law_key']\n",
    "    law_name = law_information['law_name']\n",
    "    chunks = p_c.get_jomun_information(data, law_id, law_information)\n",
    "    all_chunks.append(chunks)\n",
    "    print(f\"{law_name} 완료\")\n",
    "    p_c.save_json_file(chunks, law_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개인정보 보호법 파싱 완료 !\n",
      "고용보험법 파싱 완료 !\n",
      "교통사고처리 특례법 파싱 완료 !\n",
      "국가보안법 파싱 완료 !\n",
      "국민건강보험법 파싱 완료 !\n",
      "국민연금법 파싱 완료 !\n",
      "근로기준법 파싱 완료 !\n",
      "근로자퇴직급여 보장법 파싱 완료 !\n",
      "금융소비자 보호에 관한 법률 파싱 완료 !\n",
      "금융위원회의 설치 등에 관한 법률 파싱 완료 !\n",
      "금융회사의 지배구조에 관한 법률 파싱 완료 !\n",
      "농업협동조합법 파싱 완료 !\n",
      "대부업 등의 등록 및 금융이용자 보호에 관한 법률 파싱 완료 !\n",
      "민법 파싱 완료 !\n",
      "보험업법 파싱 완료 !\n",
      "부동산 거래신고 등에 관한 법률 파싱 완료 !\n",
      "부동산 실권리자명의 등기에 관한 법률 파싱 완료 !\n",
      "산업재해보상보험법 파싱 완료 !\n",
      "상속세 및 증여세법 파싱 완료 !\n",
      "상호저축은행법 파싱 완료 !\n",
      "새마을금고법 파싱 완료 !\n",
      "소득세법 파싱 완료 !\n",
      "신용정보의 이용 및 보호에 관한 법률 파싱 완료 !\n",
      "신용협동조합법 파싱 완료 !\n",
      "약관의 규제에 관한 법률 파싱 완료 !\n",
      "여신전문금융업법 파싱 완료 !\n",
      "예금자보호법 파싱 완료 !\n",
      "우체국예금ㆍ보험에 관한 법률 파싱 완료 !\n",
      "은행법 파싱 완료 !\n",
      "이자제한법 파싱 완료 !\n",
      "자동차손해배상 보장법 파싱 완료 !\n",
      "자본시장과 금융투자업에 관한 법률 파싱 완료 !\n",
      "재난 및 안전관리 기본법 파싱 완료 !\n",
      "전기통신사업법 파싱 완료 !\n",
      "전자금융거래법 파싱 완료 !\n",
      "전자문서 및 전자거래 기본법 파싱 완료 !\n",
      "전자서명법 파싱 완료 !\n",
      "전자정부법 파싱 완료 !\n",
      "정보통신기반 보호법 파싱 완료 !\n",
      "정보통신망 이용촉진 및 정보보호 등에 관한 법률 파싱 완료 !\n",
      "조세특례제한법 파싱 완료 !\n",
      "주민등록법 파싱 완료 !\n",
      "주택임대차보호법 파싱 완료 !\n",
      "지능정보화 기본법 파싱 완료 !\n",
      "채권의 공정한 추심에 관한 법률 파싱 완료 !\n",
      "청소년 보호법 파싱 완료 !\n",
      "클라우드컴퓨팅 발전 및 이용자 보호에 관한 법률 파싱 완료 !\n",
      "특정 금융거래정보의 보고 및 이용 등에 관한 법률 파싱 완료 !\n",
      "한국은행법 파싱 완료 !\n",
      "한국자산관리공사 설립 등에 관한 법률 파싱 완료 !\n",
      "형법 파싱 완료 !\n",
      "화재로 인한 재해보상과 보험가입에 관한 법률 파싱 완료 !\n"
     ]
    }
   ],
   "source": [
    "p_c = ParsingAndChunking()\n",
    "laws_outputs = p_c.parse_and_chunk(\"Raw/Laws\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e87c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 파일 하나로 저장\n",
    "len(laws_outputs)\n",
    "with open(\"DATA/Processed/laws_parsed.json\", \"w\", encoding = 'utf-8') as f:\n",
    "    json.dump(laws_outputs, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd3ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total : 235 -> leaf : 204 / parent : 31\n",
      "total : 241 -> leaf : 202 / parent : 39\n",
      "total : 241 -> leaf : 206 / parent : 35\n",
      "total : 244 -> leaf : 212 / parent : 32\n",
      "total : 232 -> leaf : 204 / parent : 28\n",
      "total : 242 -> leaf : 202 / parent : 40\n",
      "total : 235 -> leaf : 210 / parent : 25\n",
      "total : 234 -> leaf : 209 / parent : 25\n",
      "total : 248 -> leaf : 204 / parent : 44\n",
      "total : 226 -> leaf : 201 / parent : 25\n",
      "total : 227 -> leaf : 214 / parent : 13\n",
      "total : 239 -> leaf : 205 / parent : 34\n",
      "total : 244 -> leaf : 208 / parent : 36\n",
      "total : 241 -> leaf : 202 / parent : 39\n",
      "total : 233 -> leaf : 216 / parent : 17\n",
      "total : 238 -> leaf : 208 / parent : 30\n",
      "total : 229 -> leaf : 204 / parent : 25\n",
      "total : 245 -> leaf : 206 / parent : 39\n",
      "total : 224 -> leaf : 209 / parent : 15\n",
      "total : 244 -> leaf : 204 / parent : 40\n",
      "total : 238 -> leaf : 201 / parent : 37\n",
      "total : 243 -> leaf : 212 / parent : 31\n",
      "total : 227 -> leaf : 214 / parent : 13\n",
      "total : 245 -> leaf : 215 / parent : 30\n",
      "total : 239 -> leaf : 207 / parent : 32\n",
      "total : 245 -> leaf : 201 / parent : 44\n",
      "total : 247 -> leaf : 208 / parent : 39\n",
      "total : 245 -> leaf : 202 / parent : 43\n",
      "total : 245 -> leaf : 205 / parent : 40\n",
      "total : 243 -> leaf : 212 / parent : 31\n",
      "total : 250 -> leaf : 226 / parent : 24\n",
      "total : 240 -> leaf : 226 / parent : 14\n",
      "total : 236 -> leaf : 202 / parent : 34\n",
      "total : 230 -> leaf : 215 / parent : 15\n",
      "total : 234 -> leaf : 210 / parent : 24\n",
      "total : 241 -> leaf : 212 / parent : 29\n",
      "total : 243 -> leaf : 222 / parent : 21\n",
      "total : 242 -> leaf : 203 / parent : 39\n",
      "total : 244 -> leaf : 205 / parent : 39\n",
      "total : 243 -> leaf : 208 / parent : 35\n",
      "total : 238 -> leaf : 209 / parent : 29\n",
      "total : 233 -> leaf : 206 / parent : 27\n",
      "total : 247 -> leaf : 202 / parent : 45\n",
      "total : 226 -> leaf : 202 / parent : 24\n",
      "total : 237 -> leaf : 212 / parent : 25\n",
      "total : 250 -> leaf : 207 / parent : 43\n",
      "total : 236 -> leaf : 217 / parent : 19\n",
      "total : 244 -> leaf : 204 / parent : 40\n",
      "total : 238 -> leaf : 206 / parent : 32\n",
      "total : 240 -> leaf : 205 / parent : 35\n",
      "total : 241 -> leaf : 205 / parent : 36\n",
      "total : 244 -> leaf : 201 / parent : 43\n",
      "total : 234 -> leaf : 217 / parent : 17\n",
      "total : 237 -> leaf : 201 / parent : 36\n",
      "total : 244 -> leaf : 209 / parent : 35\n",
      "total : 240 -> leaf : 208 / parent : 32\n",
      "total : 229 -> leaf : 214 / parent : 15\n",
      "total : 249 -> leaf : 201 / parent : 48\n",
      "total : 230 -> leaf : 205 / parent : 25\n",
      "total : 243 -> leaf : 218 / parent : 25\n",
      "total : 240 -> leaf : 205 / parent : 35\n",
      "total : 229 -> leaf : 215 / parent : 14\n",
      "total : 247 -> leaf : 219 / parent : 28\n",
      "total : 234 -> leaf : 207 / parent : 27\n",
      "total : 233 -> leaf : 201 / parent : 32\n",
      "total : 237 -> leaf : 207 / parent : 30\n",
      "total : 242 -> leaf : 213 / parent : 29\n",
      "total : 250 -> leaf : 217 / parent : 33\n",
      "total : 241 -> leaf : 215 / parent : 26\n",
      "total : 240 -> leaf : 212 / parent : 28\n",
      "total : 232 -> leaf : 210 / parent : 22\n",
      "total : 246 -> leaf : 211 / parent : 35\n",
      "total : 237 -> leaf : 222 / parent : 15\n",
      "total : 233 -> leaf : 212 / parent : 21\n",
      "total : 233 -> leaf : 211 / parent : 22\n",
      "total : 250 -> leaf : 217 / parent : 33\n",
      "total : 243 -> leaf : 209 / parent : 34\n",
      "total : 228 -> leaf : 212 / parent : 16\n",
      "total : 244 -> leaf : 202 / parent : 42\n",
      "total : 248 -> leaf : 232 / parent : 16\n",
      "total : 234 -> leaf : 202 / parent : 32\n",
      "total : 224 -> leaf : 210 / parent : 14\n",
      "total : 245 -> leaf : 213 / parent : 32\n",
      "total : 246 -> leaf : 202 / parent : 44\n",
      "total : 236 -> leaf : 207 / parent : 29\n",
      "total : 243 -> leaf : 214 / parent : 29\n",
      "total : 247 -> leaf : 235 / parent : 12\n",
      "total : 234 -> leaf : 201 / parent : 33\n",
      "total : 231 -> leaf : 212 / parent : 19\n",
      "total : 244 -> leaf : 218 / parent : 26\n",
      "total : 249 -> leaf : 212 / parent : 37\n",
      "total : 233 -> leaf : 212 / parent : 21\n",
      "total : 238 -> leaf : 204 / parent : 34\n",
      "total : 244 -> leaf : 203 / parent : 41\n",
      "total : 250 -> leaf : 228 / parent : 22\n",
      "total : 234 -> leaf : 204 / parent : 30\n",
      "total : 243 -> leaf : 220 / parent : 23\n",
      "total : 236 -> leaf : 218 / parent : 18\n",
      "total : 221 -> leaf : 214 / parent : 7\n",
      "total : 247 -> leaf : 234 / parent : 13\n",
      "total : 238 -> leaf : 215 / parent : 23\n",
      "total : 250 -> leaf : 210 / parent : 40\n",
      "total : 248 -> leaf : 218 / parent : 30\n",
      "total : 247 -> leaf : 218 / parent : 29\n",
      "total : 243 -> leaf : 212 / parent : 31\n",
      "total : 216 -> leaf : 209 / parent : 7\n",
      "total : 230 -> leaf : 209 / parent : 21\n",
      "total : 242 -> leaf : 209 / parent : 33\n",
      "total : 229 -> leaf : 209 / parent : 20\n",
      "total : 240 -> leaf : 215 / parent : 25\n",
      "total : 237 -> leaf : 212 / parent : 25\n",
      "total : 226 -> leaf : 204 / parent : 22\n",
      "total : 226 -> leaf : 207 / parent : 19\n",
      "total : 231 -> leaf : 212 / parent : 19\n",
      "total : 226 -> leaf : 201 / parent : 25\n",
      "total : 247 -> leaf : 207 / parent : 40\n",
      "total : 243 -> leaf : 207 / parent : 36\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "# 길이 확인 \n",
    "p_c = ParsingAndChunking()\n",
    "lwas_folder = Path(\"DATA/Parsed\")\n",
    "parsed_law_paths = list[Path](lwas_folder.glob(\"*.json\"))\n",
    "text_lengths = []\n",
    "i = 0\n",
    "for law_path in parsed_law_paths:\n",
    "    data = p_c.read_json_file(law_path)\n",
    "    for a in data:\n",
    "        text = a[\"embedding_text\"]\n",
    "        # if len(text) > 250:\n",
    "        if len(a[\"original_text\"]) > 200:\n",
    "            # print(f\"{a['law_meta']['law_name']}- {a['chunk_id']}\")\n",
    "            print(f\"total : {len(text)} -> leaf : {len(a['original_text'])} / parent : {len(text)-len(a['original_text'])}\")\n",
    "            i += 1\n",
    "        text_lengths.append(len(text))\n",
    "print(i)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac7d8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(207.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.quantile(text_lengths, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178a88d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(35901)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long = [len < 250 for len in text_lengths]\n",
    "np.sum(long) / len(text_lengths)\n",
    "np.sum(long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b38452b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36041"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open(\"DATA/laws_parsed.json\", \"w\", encoding = 'utf-8') as f:\n",
    "#     laws_outputs = json.load(f)\n",
    "len(laws_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
